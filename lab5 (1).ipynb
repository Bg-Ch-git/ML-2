{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "449f22c9-b16d-4149-a012-99ba3cc14c5b",
      "metadata": {
        "id": "449f22c9-b16d-4149-a012-99ba3cc14c5b"
      },
      "outputs": [],
      "source": [
        "from warnings import filterwarnings\n",
        "\n",
        "filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82fa525e-1aa6-4804-b91d-239a92bfb2ac",
      "metadata": {
        "id": "82fa525e-1aa6-4804-b91d-239a92bfb2ac"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import sklearn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import typing as tp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "X_type = tp.NewType(\"X_type\", np.ndarray)\n",
        "X_row_type = tp.NewType(\"X_row_type\", np.ndarray)\n",
        "Y_type = tp.NewType(\"Y_type\", np.array)\n",
        "TS_type = tp.NewType(\"TS_type\", pd.Series)\n",
        "Model_type = tp.TypeVar(\"Model_type\")\n",
        "\n",
        "\n",
        "def read_timeseries(path_to_df: str = \"train.csv\") -> TS_type:\n",
        "    \"\"\"Функция для чтения данных и получения обучающей и тестовой выборок\"\"\"\n",
        "    df = pd.read_csv(path_to_df)\n",
        "    df = df[(df['store'] == 1) & (df['item'] == 1)]\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "    df = df.set_index(\"date\")\n",
        "    ts = df[\"sales\"]\n",
        "    train_ts = ts[:-365]\n",
        "    test_ts = ts[-365:]\n",
        "    return train_ts, test_ts\n",
        "\n",
        "\n",
        "def my_f(\n",
        "    timeseries,\n",
        "    model_idx,\n",
        "    window_size = 7\n",
        "    ):\n",
        "    row = {}\n",
        "    date = timeseries[-feature_window:].index[0]\n",
        "    row[\"dayofweek\"] = date.dayofweek\n",
        "    row[\"quarter\"] = date.quarter\n",
        "    row[\"month\"] = date.month\n",
        "    row[\"year\"] = date.year\n",
        "    row[\"dayofyear\"] = date.dayofyear\n",
        "    row[\"dayofmonth\"] = date.day\n",
        "    row[\"weekofyear\"] = date.weekofyear\n",
        "    feature_window = window_size + model_idx\n",
        "    return \n",
        "\n",
        "\n",
        "def extract_hybrid_strategy_features(\n",
        "    timeseries: TS_type,\n",
        "    model_idx: int,\n",
        "    window_size: int = 7\n",
        ") -> X_row_type:\n",
        "    \"\"\"\n",
        "    Функция для получения вектора фичей согласно гибридной схеме. На вход подаётся временной ряд\n",
        "    до момента T, функция выделяет из него фичи, необходимые модели под номером model_idx для\n",
        "    прогноза на момент времени T\n",
        "    \n",
        "    Args:\n",
        "        timeseries --- временной ряд до момента времени T (не включительно), pd.Series с датой \n",
        "                       в качестве индекса\n",
        "        model_idx --- индекс модели, то есть номер шага прогноза, \n",
        "                      для которого нужно получить признаки, нумерация с нуля\n",
        "        window_size --- количество последних значений ряда, используемых для прогноза \n",
        "                        (без учёта количества прогнозов с предыдущих этапов)\n",
        "\n",
        "    Returns:\n",
        "        Одномерный вектор фичей для модели с индексом model_idx (np.array), \n",
        "        чтобы сделать прогноз для момента времени T\n",
        "    \"\"\"\n",
        "    feature_window = window_size + model_idx\n",
        "    return timeseries[-feature_window:].values\n",
        "\n",
        "\n",
        "def build_datasets(\n",
        "    timeseries: TS_type,\n",
        "    extract_features: tp.Callable[..., X_row_type],\n",
        "    window_size: int,\n",
        "    model_count: int\n",
        ") -> tp.List[tp.Tuple[X_type, Y_type]]:\n",
        "    \"\"\"\n",
        "    Функция для получения обучающих датасетов согласно гибридной схеме\n",
        "    \n",
        "    Args:\n",
        "        timeseries --- временной ряд\n",
        "        extract_features --- функция для генерации вектора фичей\n",
        "        window_size --- количество последних значений ряда, используемых для прогноза\n",
        "        model_count --- количество моделей, используемых для получения предскзаний \n",
        "\n",
        "    Returns:\n",
        "        Список из model_count датасетов, i-й датасет используется для обучения i-й модели \n",
        "        и представляет собой пару из двумерного массива фичей и одномерного массива таргетов\n",
        "    \"\"\"\n",
        "    datasets = []\n",
        "    \n",
        "    for model_idx in range(model_count):\n",
        "        feature_window = window_size + model_idx\n",
        "        features = pd.DataFrame(\n",
        "            [extract_features(\n",
        "                timeseries[:date], model_idx, window_size=window_size\n",
        "            ) for date in timeseries.index[feature_window-1:-1]]\n",
        "        ).to_numpy()\n",
        "        \n",
        "        y = timeseries[feature_window:].values\n",
        "        \n",
        "        datasets.append((features, y))         \n",
        "    \n",
        "    \n",
        "    assert len(datasets) == model_count\n",
        "    return datasets\n",
        "\n",
        "\n",
        "def predict(\n",
        "    timeseries: TS_type,\n",
        "    models: tp.List[Model_type],\n",
        "    extract_features: tp.Callable[..., X_row_type] = extract_hybrid_strategy_features\n",
        ") -> TS_type:\n",
        "    \"\"\"\n",
        "    Функция для получения прогноза len(models) следующих значений временного ряда\n",
        "    \n",
        "    Args:\n",
        "        timeseries --- временной ряд, по которому необходимо сделать прогноз на следующие даты\n",
        "        models --- список обученных моделей, i-я модель используется для получения i-го прогноза\n",
        "        extract_features --- функция для генерации вектора фичей. Если вы реализуете свою функцию \n",
        "                             извлечения фичей для конечной модели, передавайте этим аргументом.\n",
        "                             Внутри функции predict функцию extract_features нужно вызывать только\n",
        "                             с аргументами timeseries и model_idx, остальные должны быть со значениями\n",
        "                             по умолчанию\n",
        "\n",
        "    Returns:\n",
        "        Прогноз len(models) следующих значений временного ряда\n",
        "    \"\"\"\n",
        "    forecasted_y = []\n",
        "    timeseries_ = timeseries\n",
        "    \n",
        "    for idx, model in enumerate(models):\n",
        "        features = extract_features(timeseries_, idx)\n",
        "        value = model.predict(np.array(features)[None])\n",
        "        forecasted_y.append(value[0])\n",
        "        timeseries_.at[timeseries_.index[-1] + datetime.timedelta(days=1)] = value[0]\n",
        "    \n",
        "    forecasts = pd.Series(forecasted_y)\n",
        "    forecasts.index = pd.date_range(start=timeseries.index[-1] + datetime.timedelta(days=1), periods=len(models))\n",
        "    \n",
        "    return forecasts\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "def train_models(\n",
        "    train_timeseries: TS_type,\n",
        "    model_count: int\n",
        ") -> tp.List[Model_type]:\n",
        "    \"\"\"\n",
        "    Функция для получения обученных моделей\n",
        "    \n",
        "    Args:\n",
        "        train_timeseries --- обучающий временной ряд\n",
        "        model_count --- количество моделей для обучения согласно гибридной схеме.\n",
        "                        Прогнозирование должно выполняться на model_count дней вперёд\n",
        "\n",
        "    Returns:\n",
        "        Список из len(datasets) обученных моделей\n",
        "    \"\"\"\n",
        "    models = [GradientBoostingRegressor() for _ in range(model_count)]\n",
        "    datasets = build_datasets(train_timeseries, extract_hybrid_strategy_features, window_size=7, model_count=model_count)\n",
        "    \n",
        "    for model, (X, y) in zip(models, datasets):\n",
        "        model.fit(X, y)\n",
        "   \n",
        "    \n",
        "    assert len(models) == len(datasets)\n",
        "    return models\n",
        "\n",
        "\n",
        "def score_models(\n",
        "    train_ts: TS_type,\n",
        "    test_ts: TS_type, \n",
        "    models: tp.List[Model_type],\n",
        "    predict: tp.Callable[[TS_type, tp.List[Model_type]], TS_type] = predict\n",
        "):\n",
        "    \"\"\"\n",
        "    Функция для оценки качества обученных моделей по метрике MSE\n",
        "    \n",
        "    Args:\n",
        "        train_ts --- обучающий временной ряд\n",
        "        test_ts --- тестовый временной ряд\n",
        "        models --- список обученных моделей\n",
        "        predict --- функция для получения прогноза временного ряда\n",
        "\n",
        "    Returns:\n",
        "        Усредненное MSE для прогноза моделей по всей тестовой выборке\n",
        "    \"\"\"\n",
        "    predict_len = len(models)\n",
        "    predictions = []\n",
        "    targets = []\n",
        "\n",
        "    for i in range(len(test_ts) - predict_len + 1):\n",
        "        predictions.extend(list(predict(train_ts, models)))\n",
        "        targets.extend(list(test_ts[i:i+predict_len]))\n",
        "        train_ts = train_ts.append(test_ts[i:i+1])\n",
        "\n",
        "    return sklearn.metrics.mean_squared_error(targets, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09bf00d3-0cb4-4282-8838-a99f7645275b",
      "metadata": {
        "id": "09bf00d3-0cb4-4282-8838-a99f7645275b"
      },
      "outputs": [],
      "source": [
        "train, test = read_timeseries('train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58aeb742-1e6c-4aeb-b87b-ae9adefac302",
      "metadata": {
        "tags": [],
        "id": "58aeb742-1e6c-4aeb-b87b-ae9adefac302"
      },
      "outputs": [],
      "source": [
        "def create_date_features(date):\n",
        "    \"\"\"Создает фичи из даты\"\"\"\n",
        "\n",
        "    row = {}\n",
        "    row[\"dayofweek\"] = date.dayofweek\n",
        "    row[\"quarter\"] = date.quarter\n",
        "    row[\"month\"] = date.month\n",
        "    row[\"year\"] = date.year\n",
        "    row[\"dayofyear\"] = date.dayofyear\n",
        "    row[\"dayofmonth\"] = date.day\n",
        "    row[\"weekofyear\"] = date.weekofyear\n",
        "    return row\n",
        "\n",
        "def create_only_date_train_features(y_series):\n",
        "    \"\"\"\n",
        "    Создает обучающий датасет из признаков, полученных из дат для y_series\n",
        "    \"\"\"\n",
        "\n",
        "    time_features = pd.DataFrame(\n",
        "        [create_date_features(date) for date in y_series.index]\n",
        "    )\n",
        "    return time_features, y_series\n",
        "\n",
        "\n",
        "def create_date_and_shifted_train_features(\n",
        "    y_series, shifts=5, week_seasonal_shifts=1, year_seasonal_shifts=1\n",
        "):\n",
        "    \"\"\"\n",
        "    Создает обучающий датасет из признаков, полученных из дат\n",
        "    и значений ряда ранее.\n",
        "    При этом используются значения ряда со сдвигами\n",
        "    на неделю и год назад.\n",
        "\n",
        "    Параметры:\n",
        "        - y_series\n",
        "            временной ряд.\n",
        "        - shifts\n",
        "            дневной сдвиг.\n",
        "        - week_seasonal_shifts\n",
        "            недельный сдвиг.\n",
        "        - year_seasonal_shifts\n",
        "            годовой сдвиг.\n",
        "    \"\"\"\n",
        "    \n",
        "    curr_df, y = create_only_date_train_features(y_series)\n",
        "    curr_df.index = y_series.index\n",
        "\n",
        "    # применяем сдвиг по дням\n",
        "    for shift in range(1, shifts + 1):\n",
        "        curr_df[f\"shift_{shift}\"] = y_series.shift(shift, axis=0)\n",
        "\n",
        "    # применяем сдвиг по неделям\n",
        "    for shift in range(1, week_seasonal_shifts + 1):\n",
        "        curr_df[f\"week_seasonal_shift_{shift}\"] = y_series.shift(\n",
        "            shift * 7, axis=0\n",
        "        )\n",
        "\n",
        "    # применяем сдвиг по годам\n",
        "    for shift in range(1, year_seasonal_shifts + 1):\n",
        "        curr_df[f\"year_seasonal_shift_{shift}\"] = y_series.shift(\n",
        "            shift * 365, axis=0\n",
        "        )\n",
        "    y = y_series\n",
        "\n",
        "    # удалим первые строчки с nan\n",
        "    drop_indices = curr_df.index[curr_df.isna().sum(axis=1) > 0]\n",
        "    curr_df = curr_df.drop(index=drop_indices)\n",
        "    y = y.drop(index=drop_indices)\n",
        "    return curr_df, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb51def1-e943-41b6-b0f7-68269c96ca8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb51def1-e943-41b6-b0f7-68269c96ca8d",
        "outputId": "e1b1bd95-fe7a-40b0-da58-41b95c27850d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date\n",
              "2013-01-01    13\n",
              "2013-01-02    11\n",
              "2013-01-03    14\n",
              "2013-01-04    13\n",
              "2013-01-05    10\n",
              "2013-01-06    12\n",
              "2013-01-07    10\n",
              "2013-01-08     9\n",
              "2013-01-09    12\n",
              "2013-01-10     9\n",
              "2013-01-11     9\n",
              "2013-01-12     7\n",
              "2013-01-13    10\n",
              "2013-01-14    12\n",
              "2013-01-15     5\n",
              "2013-01-16     7\n",
              "2013-01-17    16\n",
              "2013-01-18     7\n",
              "2013-01-19    18\n",
              "2013-01-20    15\n",
              "2013-01-21     8\n",
              "2013-01-22     7\n",
              "2013-01-23     9\n",
              "2013-01-24     8\n",
              "2013-01-25    14\n",
              "2013-01-26    12\n",
              "2013-01-27    12\n",
              "2013-01-28    11\n",
              "2013-01-29     6\n",
              "2013-01-30     9\n",
              "2013-01-31    13\n",
              "2013-02-01    11\n",
              "2013-02-02    21\n",
              "2013-02-03    15\n",
              "2013-02-04    14\n",
              "2013-02-05     9\n",
              "2013-02-06    10\n",
              "2013-02-07    13\n",
              "2013-02-08    11\n",
              "2013-02-09    14\n",
              "2013-02-10    11\n",
              "2013-02-11    16\n",
              "2013-02-12    11\n",
              "2013-02-13    14\n",
              "2013-02-14    10\n",
              "Name: sales, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train.head(45)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "helper = build_datasets(train, extract_hybrid_strategy_features, window_size=7, model_count=5)"
      ],
      "metadata": {
        "id": "2KdGVSrwz00r"
      },
      "id": "2KdGVSrwz00r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "helper[0][0][:6], helper[0][1][:6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2orFbmws0SvN",
        "outputId": "07568ced-3c0f-4e52-8cb4-aa68e1eb1a9b"
      },
      "id": "2orFbmws0SvN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[13, 11, 14, 13, 10, 12, 10],\n",
              "        [11, 14, 13, 10, 12, 10,  9],\n",
              "        [14, 13, 10, 12, 10,  9, 12],\n",
              "        [13, 10, 12, 10,  9, 12,  9],\n",
              "        [10, 12, 10,  9, 12,  9,  9],\n",
              "        [12, 10,  9, 12,  9,  9,  7]]),\n",
              " array([ 9, 12,  9,  9,  7, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.index[7:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATJ4sjrW0c6Q",
        "outputId": "009b9b9b-6f87-427a-b5b1-071a6508166f"
      },
      "id": "ATJ4sjrW0c6Q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatetimeIndex(['2013-01-08', '2013-01-09', '2013-01-10', '2013-01-11',\n",
              "               '2013-01-12', '2013-01-13', '2013-01-14', '2013-01-15',\n",
              "               '2013-01-16', '2013-01-17',\n",
              "               ...\n",
              "               '2016-12-22', '2016-12-23', '2016-12-24', '2016-12-25',\n",
              "               '2016-12-26', '2016-12-27', '2016-12-28', '2016-12-29',\n",
              "               '2016-12-30', '2016-12-31'],\n",
              "              dtype='datetime64[ns]', name='date', length=1454, freq=None)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_models(train, test, models = [LinearRegression.fit(helper[0][0], helper[0][1])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "apqOr0mf2UXQ",
        "outputId": "df565f77-06ee-484f-8282-3804e2978a3b"
      },
      "id": "apqOr0mf2UXQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-182e72a09cb3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhelper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZTeP0p7f7EEx"
      },
      "id": "ZTeP0p7f7EEx",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}